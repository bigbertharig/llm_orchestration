# Quick Start Guide

This document tells you how to interact with the LLM orchestration system. Read this first when starting a session.

**For deeper understanding:** [CONTEXT.md](CONTEXT.md) (project overview) | [architecture.md](architecture.md) (system design)

---

## System Overview

A distributed multi-GPU LLM orchestration system:
- **Control plane** (RPi or similar) — internet access, cloud LLM, plan submission
- **Shared drive** — mounted on control plane, NFS-shared to GPU rig
- **Brain** (local LLM on dedicated GPU(s)) — coordinates tasks, monitors workers
- **Workers** (optional, local LLMs on remaining GPUs) — execute tasks in parallel
- **Plans** — markdown files defining goals, scripts, and task dependencies

GPU assignments, models, and ports are defined in `config.json` (generated by `setup.py`).

Key runtime knobs in `config.json`:
- `brain_context_tokens` / `worker_context_tokens` - per-role Ollama context window defaults
- `timeouts.task_heartbeat_interval_seconds` - while a task is running, worker heartbeat refresh cadence (default `15`)

---

## Check System State

```bash
# Are agents running?
pgrep -af "brain.py|worker.py"

# What's loaded in Ollama?
curl -s http://localhost:11434/api/ps | jq -r '.models[].name'

# GPU memory usage
nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv,noheader

# Task queue status
ls ~/llm_orchestration/shared/tasks/{queue,processing,complete}/ 2>/dev/null | head -20
```

---

## Starting the System

If agents aren't running:

```bash
cd ~/llm_orchestration/shared/agents
python startup.py
```

**What startup.py does:**
1. Reads `config.json` for GPU assignments and models
2. Verifies hardware matches config (degrades gracefully if GPUs missing)
3. Starts brain on configured GPU(s), loads brain model
4. Reclaims configured worker ports before launching GPU agents (fail-fast if reclaim fails)
5. Starts GPU agents per config (workers start Cold by default)
6. Optionally queues startup `load_llm` meta tasks based on `initial_hot_workers`
7. System enters idle state, ready for plans

**Notes:**
- Worker LLM loading is task-driven (`load_llm` / `unload_llm` meta tasks).
- Keep worker-specific always-on Ollama services disabled to avoid competing port ownership.
- Use `python startup.py --initial-hot-workers N` to override warm-up count for one run.

First run on new hardware? Run `python setup.py` first to generate `config.json`.

---

## Submitting a Plan

```bash
cd ~/llm_orchestration
source ~/ml-env/bin/activate

python scripts/submit.py shared/plans/<plan_name> \
  --config '{"VAR1": "value1", "VAR2": "value2"}'
```

**Example - video_zim_batch:**
```bash
python scripts/submit.py shared/plans/video_zim_batch \
  --config '{
    "ZIM_PATH": "/path/to/videos.zim",
    "SOURCE_ID": "my-source",
    "OUTPUT_FOLDER": "/tmp/output"
  }'
```

Plans live in `shared/plans/`. Each has a `plan.md` defining the workflow. See [PLAN_FORMAT.md](PLAN_FORMAT.md) for how to write plans.

---

## Monitoring

```bash
# Main log - brain decisions and task flow
tail -f ~/llm_orchestration/shared/logs/brain_decisions.log

# Task queues
ls shared/tasks/queue/       # waiting for workers
ls shared/tasks/processing/  # being worked on
ls shared/tasks/complete/    # finished

# Per-task liveness heartbeats for in-flight work
ls shared/tasks/processing/*.heartbeat.json
```

### Web Dashboard

```bash
/media/bryan/shared/scripts/start_dashboard.sh
```

- Dashboard: `http://127.0.0.1:8787/`
- Controls: `http://127.0.0.1:8787/controls`
- Refresh interval: 2 seconds
- Lane tables show active-batch tasks (queue/processing/private/complete/failed) to avoid historical noise

Controls page actions:
- `Kill Plan` - remove a running batch from queue/processing/private and terminate its active work
- `Return To Default` - restart to one startup owner (`startup.py`) and reclaim duplicate/orphan agents
- `Start Plan` - submit selected plan using config JSON templates and parsed input option hints from `plan.md`

Input hints are shown next to plan settings (key, description, options) so operators can choose valid config values quickly.

### Archive Old Task Files

```bash
python ~/llm_orchestration/scripts/archive_tasks.py
```

- Moves old `tasks/complete` and `tasks/failed` entries into `tasks/archive/<batch_id>/...`
- Unbatched files are archived under `_unbatched` instead of being skipped
- Keeps active lanes cleaner for dashboard and troubleshooting

---

## Killing a Running Plan

To stop a plan mid-execution and clean up:

```bash
cd ~/llm_orchestration
source ~/ml-env/bin/activate
python scripts/kill_plan.py [batch_id]
```

**What kill_plan.py does:**
1. Kills running script processes (e.g., transcriptions)
2. Clears task queues (pending, processing, failed) and stale locks
3. Kills workers (unless `--keep-workers`)
4. Clears batch from brain state
5. Unloads worker models (brain model stays loaded)

**Options:**
- `batch_id` - Kill specific batch (optional, default: all)
- `--keep-workers` - Don't kill workers
- `--keep-models` - Don't unload worker models

---

## Stopping the System

Press `Ctrl+C` in the startup.py terminal, or:

```bash
pkill -f "brain.py|gpu.py"
```

---

## Key Paths

| Path | Purpose |
|------|---------|
| `shared/agents/` | Brain and worker code, config.json |
| `shared/core/` | Protected agent instructions (root-owned, read-only) |
| `shared/workspace/` | Documentation, ideas, human escalations |
| `shared/plans/` | Plan definitions |
| `shared/tasks/` | Task queue (queue/, processing/, complete/, failed/) |
| `shared/logs/` | Logs including brain_decisions.log |

---

## Common Issues

| Symptom | Check |
|---------|-------|
| Agents not running | `python startup.py` to start |
| Tasks stuck | Check `brain_decisions.log`, agent heartbeats, and `tasks/processing/*.heartbeat.json` freshness |
| GPU OOM | `nvidia-smi` — models may be on wrong GPUs |
| Stale state | Clear `shared/brain/state.json` active_batches |
| Config mismatch | Re-run `python setup.py` to rescan hardware |

---

## Next Steps

- **Understand the system:** [architecture.md](architecture.md)
- **Write a plan:** [PLAN_FORMAT.md](PLAN_FORMAT.md)
- **Debug brain behavior:** [brain-behavior.md](brain-behavior.md)

---

*Last Updated: February 2026*
