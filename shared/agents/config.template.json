{
  "_comment": "Generated by setup.py. Run 'python setup.py' to scan hardware and regenerate.",
  "_generated_by": "setup.py",
  "_generated_at": "",
  "_discovery_mode": "standard",
  "_hardware": {
    "hostname": "gpu-rig",
    "gpu_count": 5
  },

  "shared_path": "../",
  "permissions_path": "permissions/",
  "ollama_host": "http://localhost:11434",
  "brain_keep_alive": "30m",
  "worker_keep_alive": "30m",

  "brain": {
    "name": "brain",
    "model": "qwen2.5:32b",
    "gpus": [0]
  },

  "gpus": [
    {
      "name": "gpu-1",
      "id": 1,
      "vram_mb": 6144,
      "model": "qwen2.5:7b",
      "port": 11435,
      "permissions": "worker.json"
    },
    {
      "name": "gpu-2",
      "id": 2,
      "vram_mb": 6144,
      "model": "qwen2.5:7b",
      "port": 11436,
      "permissions": "worker.json"
    },
    {
      "name": "gpu-4",
      "id": 4,
      "vram_mb": 6144,
      "model": "qwen2.5:7b",
      "port": 11437,
      "permissions": "worker.json"
    }
  ],

  "worker_mode": "cold",
  "initial_hot_workers": 1,
  "max_hot_workers": 4,

  "timeouts": {
    "poll_interval_seconds": 5,
    "brain_think_seconds": 120,
    "worker_task_seconds": 0
  },

  "resource_limits": {
    "max_temp_c": 80,
    "gpu_temp_warning_c": 75,
    "gpu_temp_critical_c": 90,
    "cpu_temp_warning_c": 80,
    "cpu_temp_critical_c": 95,
    "max_vram_percent": 95,
    "max_power_w": 140
  },

  "retry_policy": {
    "max_attempts": 3
  },

  "thermal_pause": {
    "initial_seconds": 60,
    "max_seconds": 600,
    "backoff_factor": 2.0,
    "resume_margin_c": 3
  }
}
